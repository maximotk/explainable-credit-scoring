{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 2 / LIME Analysis\n",
        "\n",
        "LIME (Local Interpretable Model-agnostic Explanations) Analysis\n",
        "Question 6 - Part 2: Local interpretability analysis\n",
        "\n",
        "This notebook implements LIME explanations for individual predictions\n",
        "of the XGBoost credit scoring model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "import string\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_features(df: pd.DataFrame()) -> pd.DataFrame():\n",
        "    \"\"\"Get additional features - matching model training preprocessing.\"\"\"\n",
        "    df_with_features = (\n",
        "        df\n",
        "        .assign(\n",
        "            # Only revol_bal_log (not other logs)\n",
        "            revol_bal_log = np.log1p(df[\"revol_bal\"]),\n",
        "\n",
        "            # total balance\n",
        "            cur_balance = df[\"avg_cur_bal\"] * df[\"open_acc\"],\n",
        "\n",
        "            # flags\n",
        "            delinq_2yrs_flag = df[\"delinq_2yrs\"] >= 1,\n",
        "            tax_liens_flag = df[\"tax_liens\"] >= 1,\n",
        "\n",
        "            # shares\n",
        "            s_actv_bc_tl = df[\"num_actv_bc_tl\"] / (df[\"open_acc\"] + 1e-6),\n",
        "            s_bc_tl = df[\"num_bc_tl\"] / (df[\"open_acc\"] + 1e-6),\n",
        "            s_il_tl = df[\"num_il_tl\"] / (df[\"open_acc\"] + 1e-6),\n",
        "            s_rev_accts = df[\"num_rev_accts\"] / (df[\"open_acc\"] + 1e-6),\n",
        "\n",
        "            # interactions\n",
        "            revol_bal_income_ratio = df[\"revol_bal\"] / (df[\"annual_inc\"] + 1e-6),\n",
        "        )\n",
        "    )\n",
        "    return df_with_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def categorical_encoding(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Encodings of categorical variables - matching model training preprocessing.\"\"\"\n",
        "    df_encoded = df.copy()\n",
        "\n",
        "    # sub_grade to numeric\n",
        "    sg = df_encoded[\"sub_grade\"].astype(str).str.upper().str.strip()\n",
        "    letter = sg.str[0]\n",
        "    number = pd.to_numeric(sg.str[1:].str.extract(r\"(\\d+)\", expand=False), errors=\"coerce\")\n",
        "    letter_map = {ch: i+1 for i, ch in enumerate(\"ABCDEFG\")}\n",
        "    base = letter.map(letter_map)\n",
        "    sub_grade_num = (base - 1) * 5 + number\n",
        "    df_encoded[\"sub_grade_num\"] = sub_grade_num.astype(\"float32\")\n",
        "\n",
        "    # emp_length to numeric\n",
        "    emp_length_map = {\n",
        "        '< 1 year': 0, '1 year': 1, '2 years': 2, '3 years': 3, '4 years': 4,\n",
        "        '5 years': 5, '6 years': 6, '7 years': 7, '8 years': 8, '9 years': 9,\n",
        "        '10+ years': 10\n",
        "    }\n",
        "    df_encoded[\"emp_length_num\"] = df_encoded[\"emp_length\"].map(emp_length_map).astype(\"float32\")\n",
        "\n",
        "    # zip_risk encoding (instead of zip_code2)\n",
        "    # Create zip_risk categories based on zip_code\n",
        "    df_encoded[\"zip_risk\"] = pd.cut(df_encoded[\"zip_code\"], \n",
        "                                   bins=[0, 20000, 40000, 60000, 100000], \n",
        "                                   labels=[\"Low\", \"Low-Med\", \"Medium\", \"Med-High\"])\n",
        "    df_encoded = pd.get_dummies(df_encoded, columns=[\"zip_risk\"], prefix=\"zip_risk\")\n",
        "\n",
        "    # one-hot for home_ownership and purpose\n",
        "    onehot_cols = [\"home_ownership\", \"purpose\"]\n",
        "    df_encoded = pd.get_dummies(df_encoded, columns=onehot_cols, prefix=onehot_cols, drop_first=True)\n",
        "\n",
        "    # emp_title with grouped prefix (matching model)\n",
        "    df_encoded = pd.get_dummies(df_encoded, columns=[\"emp_title\"], prefix=\"emp_title_grouped\", drop_first=True)\n",
        "\n",
        "    # drop originals and unused columns\n",
        "    df_encoded = df_encoded.drop(columns=[\"grade\", \"sub_grade\", \"emp_length\", \"issue_d\", \"revol_bal\", \"zip_code\", \"Pct_afro_american\"])\n",
        "\n",
        "    return df_encoded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded successfully!\n",
            "Training set size: (868988, 112)\n",
            "Test set size: (217248, 112)\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "xgb_model = joblib.load('optimized_xgb_model.pkl')\n",
        "\n",
        "# Load and prepare data\n",
        "df = pd.read_csv(\"dataproject2025.csv\", index_col=0)\n",
        "df.drop(columns=['Predictions', 'Predicted probabilities'], inplace=True)\n",
        "df_dropped = df.dropna(axis=0)\n",
        "\n",
        "# Feature engineering\n",
        "df_engineered = get_features(df_dropped)\n",
        "df_encoded = categorical_encoding(df_engineered)\n",
        "\n",
        "# Prepare features and target\n",
        "target_col = 'target'\n",
        "X = df_encoded.drop(columns=[target_col])\n",
        "y = df_encoded[target_col]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Data loaded successfully!\")\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LIME explanations on representative test instances\n",
        "# Use training distribution to fit the explainer\n",
        "X_train_np = X_train.values if hasattr(X_train, 'values') else np.asarray(X_train)\n",
        "X_test_np = X_test.values if hasattr(X_test, 'values') else np.asarray(X_test)\n",
        "\n",
        "class_names = ['no_default', 'default']\n",
        "feature_names_list = list(X_train.columns)\n",
        "\n",
        "explainer = LimeTabularExplainer(\n",
        "    training_data=X_train_np,\n",
        "    mode='classification',\n",
        "    feature_names=feature_names_list,\n",
        "    class_names=class_names,\n",
        "    discretize_continuous=True,\n",
        "    sample_around_instance=True,\n",
        "    verbose=False,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"LIME explainer initialized successfully!\")\n",
        "print(f\"Number of features: {len(feature_names_list)}\")\n",
        "print(f\"Training samples: {X_train_np.shape[0]}\")\n",
        "print(f\"Test samples: {X_test_np.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pick representative instances to explain\n",
        "# Select instances with different predicted probabilities\n",
        "y_pred_proba = xgb_model.predict_proba(X_test_np)[:, 1]\n",
        "\n",
        "# Find instances with different risk levels\n",
        "low_risk_idx = np.where((y_pred_proba >= 0.1) & (y_pred_proba <= 0.3))[0][:1]  # Low risk\n",
        "medium_risk_idx = np.where((y_pred_proba >= 0.4) & (y_pred_proba <= 0.6))[0][:1]  # Medium risk  \n",
        "high_risk_idx = np.where((y_pred_proba >= 0.7) & (y_pred_proba <= 0.9))[0][:1]  # High risk\n",
        "\n",
        "indices_to_explain = np.concatenate([low_risk_idx, medium_risk_idx, high_risk_idx])\n",
        "\n",
        "print(\"Selected instances for LIME analysis:\")\n",
        "for i, idx in enumerate(indices_to_explain):\n",
        "    actual_label = y_test.iloc[idx] if hasattr(y_test, 'iloc') else y_test[idx]\n",
        "    pred_proba = y_pred_proba[idx]\n",
        "    print(f\"Instance {i+1} (Index {idx}): Predicted probability = {pred_proba:.3f}, Actual label = {actual_label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate LIME explanations\n",
        "def predict_fn(data):\n",
        "    \"\"\"Prediction function for LIME\"\"\"\n",
        "    return xgb_model.predict_proba(data)\n",
        "\n",
        "lime_results = []\n",
        "for idx in indices_to_explain:\n",
        "    instance = X_test_np[idx]\n",
        "    exp = explainer.explain_instance(\n",
        "        data_row=instance,\n",
        "        predict_fn=predict_fn,\n",
        "        num_features=10,  # Top 10 features\n",
        "        top_labels=2,     # Both classes\n",
        "    )\n",
        "    lime_results.append((idx, exp))\n",
        "\n",
        "print(\"LIME explanations generated successfully!\")\n",
        "print(f\"Analyzed {len(lime_results)} instances\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display LIME explanations\n",
        "for i, (idx, exp) in enumerate(lime_results):\n",
        "    actual_label = y_test.iloc[idx] if hasattr(y_test, 'iloc') else y_test[idx]\n",
        "    pred_proba = y_pred_proba[idx]\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"LIME EXPLANATION - Instance {i+1} (Index {idx})\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Predicted probability of default: {pred_proba:.3f}\")\n",
        "    print(f\"Actual label: {'Default' if actual_label == 1 else 'No Default'}\")\n",
        "    print(f\"Prediction: {'High Risk' if pred_proba > 0.5 else 'Low Risk'}\")\n",
        "    \n",
        "    # Get explanation for the predicted class\n",
        "    predicted_class = 1 if pred_proba > 0.5 else 0\n",
        "    explanation = exp.as_list(label=predicted_class)\n",
        "    \n",
        "    print(f\"\\nTop 10 features contributing to prediction:\")\n",
        "    print(\"-\" * 50)\n",
        "    for feature, weight in explanation:\n",
        "        print(f\"{feature:<30} {weight:>8.4f}\")\n",
        "    \n",
        "    print(f\"\\nFeature values for this instance:\")\n",
        "    print(\"-\" * 50)\n",
        "    instance_data = X_test.iloc[idx] if hasattr(X_test, 'iloc') else pd.Series(X_test_np[idx], index=feature_names_list)\n",
        "    for feature, _ in explanation[:5]:  # Show top 5 features\n",
        "        if feature in instance_data.index:\n",
        "            print(f\"{feature:<30} {instance_data[feature]:>8.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize LIME explanations\n",
        "fig, axes = plt.subplots(1, len(lime_results), figsize=(15, 5))\n",
        "if len(lime_results) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "for i, (idx, exp) in enumerate(lime_results):\n",
        "    actual_label = y_test.iloc[idx] if hasattr(y_test, 'iloc') else y_test[idx]\n",
        "    pred_proba = y_pred_proba[idx]\n",
        "    predicted_class = 1 if pred_proba > 0.5 else 0\n",
        "    \n",
        "    # Create LIME plot manually\n",
        "    explanation = exp.as_list(label=predicted_class)\n",
        "    \n",
        "    # Extract features and weights\n",
        "    features = [x[0] for x in explanation]\n",
        "    weights = [x[1] for x in explanation]\n",
        "    \n",
        "    # Create horizontal bar plot\n",
        "    y_pos = np.arange(len(features))\n",
        "    colors = ['red' if w > 0 else 'green' for w in weights]\n",
        "    \n",
        "    axes[i].barh(y_pos, weights, color=colors, alpha=0.7)\n",
        "    axes[i].set_yticks(y_pos)\n",
        "    axes[i].set_yticklabels(features)\n",
        "    axes[i].set_xlabel('Feature Weight')\n",
        "    axes[i].axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
        "    axes[i].set_title(f'Instance {i+1}: P(default)={pred_proba:.3f}\\nActual: {\"Default\" if actual_label==1 else \"No Default\"}')\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Part 2 / LIME Analysis: Local Explanations for Individual Predictions', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LIME Analysis Summary\n",
        "\n",
        "### What LIME Shows Us:\n",
        "\n",
        "**1. Local Interpretability**\n",
        "- LIME explains **why** the model made a specific prediction for individual instances\n",
        "- Each explanation shows which features contributed most to that particular decision\n",
        "- Features are ranked by their importance for that specific prediction\n",
        "\n",
        "**2. Feature Contributions**\n",
        "- **Positive weights**: Features that increase the probability of default\n",
        "- **Negative weights**: Features that decrease the probability of default\n",
        "- **Magnitude**: How much each feature influenced the prediction\n",
        "\n",
        "**3. Business Value**\n",
        "- **Transparency**: Explain individual loan decisions to customers\n",
        "- **Debugging**: Understand why certain predictions seem wrong\n",
        "- **Validation**: Verify that the model uses sensible features for decisions\n",
        "- **Compliance**: Meet regulatory requirements for explainable AI\n",
        "\n",
        "### Key Insights:\n",
        "- Different instances can have very different explanations even with similar predictions\n",
        "- The same feature can have opposite effects depending on the individual's profile\n",
        "- LIME helps identify which specific factors drove each lending decision\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
